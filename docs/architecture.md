# ðŸ—ï¸ Technical Architecture

## System Overview

ai-clone-builder is built with a modular, extensible architecture designed for rapid iteration and easy scaling.

## ðŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CLI Interface  â”‚  Quick Start  â”‚  Test Scripts  â”‚  Future  â”‚
â”‚   (rich UI)     â”‚   (demos)     â”‚  (diagnostics) â”‚   (web)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CORE SYSTEMS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           â”‚              â”‚                â”‚                 â”‚
â”‚ Personalityâ”‚  AI Clone    â”‚ Conversation  â”‚    Memory       â”‚
â”‚  System    â”‚   Engine     â”‚   Manager     â”‚   System        â”‚
â”‚           â”‚              â”‚                â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Question-â”‚â”‚ â”‚AIClone   â”‚ â”‚ â”‚CloneConvo  â”‚â”‚ â”‚SimpleMemory â”‚ â”‚
â”‚ â”‚naire    â”‚â”‚ â”‚Class     â”‚ â”‚ â”‚System      â”‚â”‚ â”‚& ConvoMgr   â”‚ â”‚
â”‚ â”‚         â”‚â”‚ â”‚          â”‚ â”‚ â”‚            â”‚â”‚ â”‚             â”‚ â”‚
â”‚ â”‚Template â”‚â”‚ â”‚Personalityâ”‚ â”‚ â”‚Scenarios   â”‚â”‚ â”‚JSON Storage â”‚ â”‚
â”‚ â”‚Engine   â”‚â”‚ â”‚Prompts   â”‚ â”‚ â”‚Turn Logic  â”‚â”‚ â”‚Context Mgmt â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 EXTERNAL SYSTEMS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              â”‚                              â”‚
â”‚        Ollama + LLaMA        â”‚       File System           â”‚
â”‚                              â”‚                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                          â”‚ â”‚ â”‚                          â”‚ â”‚
â”‚ â”‚  LLaMA 3.2:3b Model      â”‚ â”‚ â”‚  data/personalities/     â”‚ â”‚
â”‚ â”‚  Local HTTP API          â”‚ â”‚ â”‚  data/conversations/     â”‚ â”‚
â”‚ â”‚  Text Generation         â”‚ â”‚ â”‚  JSON Configuration      â”‚ â”‚
â”‚ â”‚                          â”‚ â”‚ â”‚                          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ§© Core Components

### 1. Personality System (`src/personality/`)

**Purpose**: Convert human personality traits into AI prompts

**Components**:
- `questionnaire.py` - Interactive personality collection
- `templates.py` - Prompt generation from personality data

**Data Flow**:
```
User Input â†’ Questionnaire â†’ Personality JSON â†’ System Prompt
```

**Key Classes**:
```python
PersonalityQuestionnaire
â”œâ”€â”€ run_questionnaire() -> Dict[personality_data]
â”œâ”€â”€ save_personality() -> str[filename]
â””â”€â”€ load_personality() -> Dict[personality_data]

PersonalityTemplate
â”œâ”€â”€ create_system_prompt() -> str[prompt]
â”œâ”€â”€ _build_communication_style() -> str
â”œâ”€â”€ _build_personality_description() -> str
â””â”€â”€ _build_interests_description() -> str
```

### 2. AI Clone Engine (`src/ai_clone/`)

**Purpose**: Create and manage individual AI personalities

**Components**:
- `clone.py` - Main AIClone class with Ollama integration
- `conversation.py` - Clone-to-clone conversation management

**Data Flow**:
```
Personality Data â†’ AIClone â†’ Ollama API â†’ Response â†’ Memory Update
```

**Key Classes**:
```python
AIClone
â”œâ”€â”€ __init__(personality_data) -> Sets up system prompt
â”œâ”€â”€ respond(message, context) -> str[ai_response]
â”œâ”€â”€ add_to_conversation_history() -> Updates memory
â”œâ”€â”€ get_recent_history() -> List[messages]
â””â”€â”€ save_conversation() -> str[filename]

CloneConversation
â”œâ”€â”€ start_conversation(scenario) -> str[conv_id]
â”œâ”€â”€ run_conversation() -> List[conversation_history]
â”œâ”€â”€ _display_message() -> Rich UI output
â””â”€â”€ _should_end_conversation() -> bool
```

### 3. Memory System (`src/memory/`)

**Purpose**: Handle conversation history and context

**Components**:
- `simple_memory.py` - JSON-based memory and conversation management

**Data Flow**:
```
Messages â†’ SimpleMemory â†’ JSON Files â†’ Context Retrieval
```

**Key Classes**:
```python
SimpleMemory
â”œâ”€â”€ add_message(speaker, content) -> Stores message
â”œâ”€â”€ get_recent_messages(count) -> List[messages]
â”œâ”€â”€ search_messages(query) -> List[matching_messages]
â””â”€â”€ save_memory() -> JSON file

ConversationManager  
â”œâ”€â”€ start_conversation() -> str[conv_id]
â”œâ”€â”€ add_message_to_conversation() -> Updates conversation
â”œâ”€â”€ end_conversation() -> Archives conversation
â””â”€â”€ save_conversation_log() -> JSON file
```

### 4. Interface System (`src/interface/`)

**Purpose**: User interaction and system control

**Components**:
- `cli.py` - Full-featured command-line interface

**Data Flow**:
```
User Input â†’ CLI Menu â†’ Core Systems â†’ Rich UI Output
```

**Key Classes**:
```python
AICloneCLI
â”œâ”€â”€ show_main_menu() -> Rich table display
â”œâ”€â”€ create_new_clone() -> Questionnaire workflow
â”œâ”€â”€ chat_with_clone() -> Interactive chat
â”œâ”€â”€ clone_to_clone_conversation() -> Conversation setup
â””â”€â”€ run() -> Main application loop
```

## ðŸ”„ Data Flow Diagrams

### Personality Creation Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    User     â”‚â”€â”€â”€â–¶â”‚Questionnaire â”‚â”€â”€â”€â–¶â”‚Personality  â”‚
â”‚   Input     â”‚    â”‚   System     â”‚    â”‚    JSON     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Clone    â”‚â—€â”€â”€â”€â”‚   Template   â”‚â—€â”€â”€â”€â”‚ System      â”‚
â”‚   Ready     â”‚    â”‚   Engine     â”‚    â”‚  Prompt     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Conversation Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Message   â”‚â”€â”€â”€â–¶â”‚  AI Clone    â”‚â”€â”€â”€â–¶â”‚  Ollama     â”‚
â”‚   Input     â”‚    â”‚  + Context   â”‚    â”‚    API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Memory    â”‚â—€â”€â”€â”€â”‚  Response    â”‚â—€â”€â”€â”€â”‚   LLaMA     â”‚
â”‚  Storage    â”‚    â”‚ Processing   â”‚    â”‚  Response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Clone-to-Clone Conversation
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Clone A   â”‚â”€â”€â”€â–¶â”‚Conversation  â”‚â”€â”€â”€â–¶â”‚   Clone B   â”‚
â”‚  (Speaker)  â”‚    â”‚   Manager    â”‚    â”‚ (Listener)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                   â”‚                   â”‚
       â”‚                   â–¼                   â–¼
       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            â”‚   Message    â”‚    â”‚   Message   â”‚
       â”‚            â”‚   Storage    â”‚    â”‚ Processing  â”‚
       â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â”‚                   â–¼                   â–¼
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Response
```

## ðŸ—„ï¸ Data Structures

### Personality Data Schema
```json
{
  "clone_name": "string",
  "basic_info": {
    "name": "string",
    "age": "string", 
    "location": "string",
    "occupation": "string"
  },
  "communication_style": {
    "formality": {"choice": "string", "index": "number"},
    "humor": {"choice": "string", "index": "number"},
    "expressiveness": {"choice": "string", "index": "number"},
    "response_length": {"choice": "string", "index": "number"}
  },
  "personality_traits": {
    "extroversion": {"choice": "string", "index": "number"},
    "openness": {"choice": "string", "index": "number"}, 
    "emotional_style": {"choice": "string", "index": "number"},
    "decision_making": {"choice": "string", "index": "number"}
  },
  "interests": {
    "hobbies": "string",
    "topics": "string", 
    "values": "string",
    "conversation_starters": "string"
  }
}
```

### Conversation History Schema
```json
{
  "id": "string",
  "participants": ["string", "string"],
  "scenario": "string",
  "started_at": "ISO_timestamp",
  "ended_at": "ISO_timestamp", 
  "status": "active|ended",
  "messages": [
    {
      "timestamp": "ISO_timestamp",
      "speaker": "string",
      "content": "string"
    }
  ]
}
```

## âš™ï¸ Configuration & Settings

### Ollama Configuration
```python
OLLAMA_HOST = "http://localhost:11434"
MODEL_NAME = "llama3.2:3b"
GENERATION_PARAMS = {
    "temperature": 0.7,
    "top_p": 0.9, 
    "max_tokens": 150
}
```

### File System Layout
```
data/
â”œâ”€â”€ personalities/          # Personality JSON files
â”‚   â”œâ”€â”€ {name}_personality.json
â”‚   â””â”€â”€ .gitkeep
â””â”€â”€ conversations/          # Conversation logs
    â”œâ”€â”€ {clone1}_{clone2}_{timestamp}.json
    â”œâ”€â”€ conversation_{id}.json
    â””â”€â”€ .gitkeep
```

### Error Handling Strategy

**Connection Errors**:
- Ollama connection testing on startup
- Graceful degradation with helpful error messages
- Setup guidance for common issues

**Data Errors**:
- JSON validation for personality files
- Backup conversation data on errors
- Recovery mechanisms for corrupted data

**User Input Errors**:
- Input validation with retry prompts
- Clear error messages with suggested fixes
- Graceful handling of interrupts (Ctrl+C)

## ðŸ”Œ Extension Points

### Adding New Memory Systems
```python
# Implement this interface
class MemoryInterface:
    def add_message(self, speaker: str, content: str) -> None
    def get_recent_messages(self, count: int) -> List[Dict]
    def search_messages(self, query: str) -> List[Dict]
```

### Adding New AI Models
```python
# Implement this interface  
class AIModelInterface:
    def respond(self, prompt: str, context: List[Dict]) -> str
    def test_connection(self) -> bool
```

### Adding New Interfaces
```python
# Implement this interface
class InterfaceInterface:
    def show_menu(self) -> None
    def handle_input(self, choice: str) -> None
    def display_response(self, message: str) -> None
```

## ðŸš€ Performance Considerations

### Memory Usage
- **Personality data**: ~5-50KB per clone
- **Conversation history**: ~1-5KB per message
- **Model memory**: ~4GB for LLaMA 3.2:3b
- **Application memory**: ~50-100MB

### Response Times
- **Cold start**: 5-10 seconds (model loading)
- **Warm responses**: 2-5 seconds per message
- **Context processing**: <1 second
- **File I/O**: <100ms

### Scalability Limits (Current)
- **Concurrent clones**: 2-5 (memory limited)
- **Conversation history**: 1000+ messages per clone
- **Personality files**: 100+ clones
- **Storage growth**: ~1MB per 1000 messages

---

**Next**: Check out the [Setup Guide](./setup-guide.md) for installation instructions! 